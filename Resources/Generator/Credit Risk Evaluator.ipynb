{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('2020Q1loans.csv'))\n",
    "\n",
    "# train_df.head()\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model Prediction\n",
    "\n",
    "I predict that the random forest classifier will be a better model than the logistic regression. The logistic regression methods classifies based on where the data point is nearest or closest to other points. Where as the random forest ask a series of true false to make a determination of best fit. Becasue the LendingClub is trying to determine high and low risk loans it may be best to use a series of true/false decisions rather than where a point of data is located or closesly resembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "\n",
    "X_Train = pd.get_dummies(train_df.drop(columns=['target']))\n",
    "Y_Train = train_df['target']\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "\n",
    "X_Test = pd.get_dummies(test_df.drop(columns=['target']))\n",
    "Y_Test = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set (2020) to prevent errors \n",
    "\n",
    "for column in X_Train.columns:\n",
    "    if column not in X_Test.columns:\n",
    "        X_Test[column] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5072309655465759"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "xclassifier = LogisticRegression()\n",
    "xclassifier.fit(X_Train, Y_Train)\n",
    "xclassifier.score(X_Test,Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6356869417269247"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "RForest = RandomForestClassifier()\n",
    "RForest.fit(X_Train, Y_Train)\n",
    "RForest.score(X_Test,Y_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although both models have relatively low scores, my prediction that the Random Forest model was better is correct. \n",
    "After the data is scaled, I beleive both scores will increase, but the Random Forest model will still perform better. \n",
    "Because both model were done using unscaled data, I think scale data will only validate my intial prediction even more. The logic behind the models will not change, but scaling will allow for better accuracy in both models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data - putting data on even playing field\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Xscale = StandardScaler()\n",
    "Xscale.fit(X_Train)\n",
    "\n",
    "XTrain_scaled = Xscale.transform(X_Train)\n",
    "XTest_scaled = Xscale.transform(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598894087622289"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "\n",
    "xclassifier = LogisticRegression()\n",
    "xclassifier.fit(XTrain_scaled, Y_Train)\n",
    "xclassifier.score(XTest_scaled,Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.635899617184177"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "\n",
    "RForest = RandomForestClassifier()\n",
    "RForest.fit(XTrain_scaled, Y_Train)\n",
    "RForest.score(XTest_scaled,Y_Test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! The logistic regression model actually performed better. I'm not sure why. Maybe the scaling of the data put things in the right perceptive and that is why. Maybe unscaling gave the radom classifier model an unfair advantage. My prediction is incorrect this time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
